# Abstract

This project presents a comprehensive analysis of deploying various **Large Language Models (LLMs)**, including GPT, Llama, and other fine-tuned and open-source LLMs, across different computing environmentsâ€”edge, cloud, and server platforms. The core objective is to assess the adaptability and efficiency of these advanced models in diverse operational contexts. We have meticulously designed a suite of tasks to quantify the performance and accuracy of LLMs in each environment. These tasks are tailored to evaluate key metrics such as response time, computational resource utilization, and model accuracy under varying workloads and hardware configurations. The study offers insights into the scalability and environmental suitability of LLMs, providing a nuanced understanding of their deployment implications. This research is pivotal for organizations strategizing the integration of LLMs into their operational framework, ensuring optimal balance between computational efficiency and model efficacy. The outcomes of this project are expected to guide future developments in LLM deployment strategies, particularly in making informed decisions about the appropriate computing environment for specific applications.







# Team

* Zhuohao Li 
* Ying Li

# Required Submissions

* [Proposal](proposal)
* [Midterm Checkpoint Presentation Slides](http://)
* [Final Presentation Slides](http://)
* [Final Report](report)
